<h1 id="foundations-of-frequentist-statistics">Foundations of
Frequentist Statistics</h1>
<p>In this chapter, we embark on a journey into the heart of frequentist
statistical inference—a framework that dominates modern empirical
research. At its core, frequentist statistics is about making
observations from a sample and then drawing inferences about the broader
population from which that sample was drawn. The fundamental question we
seek to answer is: <em>How confident can we be that the patterns we
observe in our limited sample reflect true patterns in the
population?</em></p>
<p>By the end of this chapter, you will understand the foundational
concepts that underpin frequentist inference, including the philosophy
of repeated sampling, the nature of estimators, and the mathematical
criteria we use to distinguish good estimators from poor ones.</p>
<h2 id="the-nature-of-inferential-statistics">The Nature of Inferential
Statistics</h2>
<section id="what-are-we-really-doing" class="callout-note"
data-icon="false">
<h2>What Are We Really Doing?</h2>
<p>Inferential statistics is fundamentally about making observations in
<strong>sample data</strong> and then attempting to extrapolate causal
connections or patterns to the <strong>population data</strong>. When we
successfully extrapolate these connections, we say our results are
<strong>statistically significant</strong>. When we cannot extrapolate
with confidence, we say our results are <strong>not statistically
significant</strong>.</p>
</section>
<p>This distinction—between what we observe in our sample and what we
can confidently claim about the population—lies at the heart of all
inferential statistics. But what exactly are we making claims about when
we talk about populations?</p>
<h3 id="population-parameters-vs.-sample-statistics">Population
Parameters vs. Sample Statistics</h3>
<p>When we make claims about a population, we are not making claims
about individual observations. After all, populations are conceptually
infinite in size. Instead, we make claims about specific
<strong>parameters</strong> of the population’s distribution. The two
parameters we encounter most frequently are:</p>
<ol type="1">
<li><p><strong>The population mean</strong> (<span
class="math inline">\mu</span>): This is by far the most common
parameter we test hypotheses about in applied statistics.</p></li>
<li><p><strong>The population variance</strong> (<span
class="math inline">\sigma^2</span>): This parameter is crucial because
tests for the population mean often depend on our ability to estimate
the population variance.</p></li>
</ol>
<p>Because we never truly know the values of <span
class="math inline">\mu</span> or <span
class="math inline">\sigma^2</span>, we must estimate them using sample
data. The corresponding quantities we calculate from our sample are:</p>
<ul>
<li><strong>Sample mean</strong> (<span
class="math inline">\bar{y}</span>): The analog to the population
mean</li>
<li><strong>Sample variance</strong> (<span
class="math inline">s^2</span>): The analog to the population
variance</li>
</ul>
<section id="a-critical-distinction" class="callout-important"
data-icon="false">
<h2>A Critical Distinction</h2>
<p>When we call the sample mean and sample variance “analogs” or
“counterparts” to their population equivalents, we mean only that they
correspond conceptually. We are <em>not</em> claiming they are equal or
even necessarily good estimates. Establishing which sample statistics
make good estimators of population parameters is precisely what this
chapter is about.</p>
</section>
<h2 id="transformations-of-random-variables">Transformations of Random
Variables</h2>
<p>Before we dive into the philosophy of estimation, we need to develop
some mathematical machinery. In statistics, we routinely transform
data—we take numbers, apply formulas to them, and generate new numbers.
Understanding how these transformations affect the mean and variance of
our data is essential.</p>
<h3 id="affine-transformations">Affine Transformations</h3>
<p>Consider a simple but powerful type of transformation called an
<strong>affine transformation</strong>. If we have a random variable
<span class="math inline">X</span> with mean <span
class="math inline">\bar{x}</span> and variance <span
class="math inline">s^2</span>, we might create a new variable:</p>
<p><span class="math display">Y = mX + c</span></p>
<p>where <span class="math inline">m</span> is a multiplicative constant
(the slope) and <span class="math inline">c</span> is an additive
constant (the intercept). This is exactly the form of a linear equation
you’ve seen since high school algebra.</p>
<p>The question is: if we know the mean and variance of <span
class="math inline">X</span>, what are the mean and variance of <span
class="math inline">Y</span>?</p>
<p>We can decompose this affine transformation into two simpler
operations:</p>
<ol type="1">
<li><strong>Translation</strong>: <span class="math inline">X
\rightarrow X + c</span> (adding a constant)</li>
<li><strong>Linear transformation</strong>: <span class="math inline">X
\rightarrow mX</span> (multiplying by a constant)</li>
</ol>
<h4 id="properties-of-translation">Properties of Translation</h4>
<p>When you add a constant <span class="math inline">c</span> to every
value in your dataset, creating <span class="math inline">Y = X +
c</span>:</p>
<p><span class="math display">
\begin{aligned}
\text{Mean of } Y &amp;= \bar{x} + c \\
\text{Variance of } Y &amp;= s^2
\end{aligned}
</span></p>
<p>The mean shifts by exactly <span class="math inline">c</span>, but
the variance remains unchanged. Why? Because variance measures the
spread of data around the mean, and when you shift all values by the
same amount, their relative positions don’t change.</p>
<section id="connecting-to-earlier-concepts" class="callout-tip"
data-icon="false">
<h2>Connecting to Earlier Concepts</h2>
<p>You’ve already encountered this idea when we discussed the <span
class="math inline">z</span>-transformation. When we subtract the mean
from a variable, we’re performing a translation that shifts the entire
distribution to have mean zero. The shape and spread of the distribution
remain the same.</p>
</section>
<h4 id="properties-of-linear-transformation">Properties of Linear
Transformation</h4>
<p>When you multiply every value by a constant <span
class="math inline">m</span>, creating <span class="math inline">Y =
mX</span>:</p>
<p><span class="math display">
\begin{aligned}
\text{Mean of } Y &amp;= m\bar{x} \\
\text{Variance of } Y &amp;= m^2 s^2 \\
\text{Standard deviation of } Y &amp;= |m| s
\end{aligned}
</span></p>
<p>Notice that the variance is multiplied by <span
class="math inline">m^2</span>, not <span class="math inline">m</span>.
This occurs because variance involves squared deviations, so a
multiplicative constant gets squared in the process.</p>
<h4 id="combining-both-transformations">Combining Both
Transformations</h4>
<p>For the full affine transformation <span class="math inline">Y = mX +
c</span>:</p>
<p><span class="math display">
\begin{aligned}
\text{Mean of } Y &amp;= m\bar{x} + c \\
\text{Variance of } Y &amp;= m^2 s^2 \\
\text{Standard deviation of } Y &amp;= |m| s
\end{aligned}
</span></p>
<p>These formulas will prove invaluable as we develop more sophisticated
statistical techniques.</p>
<h2 id="the-frequentist-philosophy-repeated-sampling">The Frequentist
Philosophy: Repeated Sampling</h2>
<p>We now arrive at the conceptual heart of frequentist statistics. The
entire edifice of frequentist inference rests on an imaginary exercise:
<strong>repeated sampling</strong>.</p>
<section id="the-thought-experiment" class="callout-note"
data-icon="false">
<h2>The Thought Experiment</h2>
<p>Imagine that we could:</p>
<ol type="1">
<li>Draw a random sample from the population</li>
<li>Calculate some statistic from that sample</li>
<li>Return the sample to the population</li>
<li>Draw another random sample</li>
<li>Calculate the statistic again</li>
<li>Repeat this process infinitely many times</li>
</ol>
<p>This thought experiment—sampling repeatedly from the same
population—forms the foundation for how we evaluate estimators in
frequentist statistics.</p>
</section>
<p>Here’s the crucial point: <em>in practice, we only sample once</em>.
But theoretically, we imagine what would happen if we could sample
infinitely many times. The behavior of our estimator across these
hypothetical repeated samples tells us whether it’s a good estimator or
not.</p>
<h3 id="the-concept-of-an-estimator">The Concept of an Estimator</h3>
<p>An <strong>estimator</strong> is simply a formula that we apply to
sample data to estimate a population parameter. Importantly, there are
infinitely many possible estimators for any given parameter.</p>
<p>For example, suppose we want to estimate the population mean <span
class="math inline">\mu</span>. Here are just a few of the infinitely
many estimators we could choose:</p>
<ul>
<li>The first observation: <span class="math inline">\hat{\mu}_1 =
y_1</span></li>
<li>The sum of the first two observations: <span
class="math inline">\hat{\mu}_2 = y_1 + y_2</span></li>
<li>The cube of the first observation: <span
class="math inline">\hat{\mu}_3 = y_1^3</span></li>
<li>The fourth power of the seventh observation times the sine of the
second: <span class="math inline">\hat{\mu}_4 = y_7^4 \times
\sin(y_2)</span></li>
<li>The sample mean: <span class="math inline">\hat{\mu}_5 = \bar{y} =
\frac{1}{n}\sum_{i=1}^{n} y_i</span></li>
</ul>
<p>Most of these are obviously terrible estimators. But the point is
that we can construct any formula we want, and each formula defines a
different estimator. The set of all possible estimators is infinite.</p>
<p>So how do we choose among them? How do we determine which estimators
are “good” and which are “bad”?</p>
<p>The answer lies in examining the <strong>sampling
distribution</strong> of each estimator.</p>
<h3 id="sampling-distributions">Sampling Distributions</h3>
<p>For any estimator, we can imagine the repeated sampling process:</p>
<ol type="1">
<li>Draw a sample of size <span class="math inline">n</span></li>
<li>Apply the estimator to get an estimate</li>
<li>Record that estimate</li>
<li>Repeat infinitely many times</li>
</ol>
<p>The distribution of all these estimates is called the
<strong>sampling distribution</strong> of the estimator. Each different
estimator has its own sampling distribution.</p>
<section id="key-insight" class="callout-important" data-icon="false">
<h2>Key Insight</h2>
<p>The sampling distribution is a theoretical construct. We never
actually observe it because we only sample once in practice. But by
imagining what it would look like, we can develop mathematical criteria
for judging the quality of different estimators.</p>
</section>
<h2 id="a-concrete-example-estimating-from-a-simple-population">A
Concrete Example: Estimating from a Simple Population</h2>
<p>To make these abstract ideas concrete, let’s work through a simple
example. Consider a population with only three values: <span
class="math inline">\{1, 2, 3\}</span>. Since there’s one of each value,
each has probability <span class="math inline">1/3</span> of being
selected if we draw randomly from this population.</p>
<h3 id="the-true-population-parameters">The True Population
Parameters</h3>
<p>This is a discrete uniform distribution, and we can easily calculate
the true population mean and variance:</p>
<p><span class="math display">
\mu = \mathbb{E}[Y] = 1 \cdot \frac{1}{3} + 2 \cdot \frac{1}{3} + 3
\cdot \frac{1}{3} = 2
</span></p>
<p>For the variance, we first calculate the expected value of <span
class="math inline">Y^2</span>:</p>
<p><span class="math display">
\mathbb{E}[Y^2] = 1^2 \cdot \frac{1}{3} + 2^2 \cdot \frac{1}{3} + 3^2
\cdot \frac{1}{3} = \frac{14}{3}
</span></p>
<p>Then, using the formula <span class="math inline">\mathrm{Var}(Y) =
\mathbb{E}[Y^2] - (\mathbb{E}[Y])^2</span>:</p>
<p><span class="math display">
\sigma^2 = \frac{14}{3} - 2^2 = \frac{14}{3} - 4 = \frac{2}{3}
</span></p>
<p>We can also verify this directly by calculating the squared
deviations:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Value (<span
class="math inline">y</span>)</th>
<th style="text-align: center;">Deviation (<span class="math inline">y -
\mu</span>)</th>
<th style="text-align: center;">Squared Deviation (<span
class="math inline">y - \mu</span>)²</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p><span class="math display">
\sigma^2 = \frac{1 + 0 + 1}{3} = \frac{2}{3}
</span></p>
<p>So we know that <span class="math inline">\mu = 2</span> and <span
class="math inline">\sigma^2 = 2/3</span>. In practice, we wouldn’t know
these values—we’d have to estimate them from sample data. But in this
pedagogical example, knowing them allows us to evaluate how well
different estimators perform.</p>
<h3 id="using-a-single-observation-as-an-estimator">Using a Single
Observation as an Estimator</h3>
<p>Suppose we draw a single observation from this population. Can we use
it to estimate the population mean? According to frequentist thinking,
the surprising answer is yes—at least by one important criterion.</p>
<p>Consider the estimator <span class="math inline">\hat{\mu} =
Y_1</span>, where <span class="math inline">Y_1</span> is our single
observation. To evaluate this estimator, we imagine drawing infinitely
many samples (each of size 1) and recording each estimate. What would
the sampling distribution look like?</p>
<p>Since each draw yields 1, 2, or 3 with equal probability, our
estimates would be: - <span class="math inline">\hat{\mu} = 1</span>
one-third of the time - <span class="math inline">\hat{\mu} = 2</span>
one-third of the time - <span class="math inline">\hat{\mu} = 3</span>
one-third of the time</p>
<p>The mean of this sampling distribution is:</p>
<p><span class="math display">
\mathbb{E}[\hat{\mu}] = 1 \cdot \frac{1}{3} + 2 \cdot \frac{1}{3} + 3
\cdot \frac{1}{3} = 2 = \mu
</span></p>
<p>The expected value of our estimator equals the population mean! This
means that on average, across infinitely many samples, our estimator
hits the target.</p>
<h2 id="properties-of-estimators">Properties of Estimators</h2>
<p>We’ve just discovered our first desirable property of estimators:
<strong>unbiasedness</strong>. Let’s now systematically examine the key
properties that statisticians use to evaluate estimators.</p>
<h3 id="unbiasedness-accuracy-on-average">Unbiasedness: Accuracy on
Average</h3>
<section id="definition-unbiasedness" class="callout-important"
data-icon="false">
<h2>Definition: Unbiasedness</h2>
<p>An estimator <span class="math inline">\hat{\theta}</span> is
<strong>unbiased</strong> for a parameter <span
class="math inline">\theta</span> if its expected value equals the
parameter:</p>
<p><span class="math display">
\mathbb{E}[\hat{\theta}] = \theta
</span></p>
<p>In words: on average across all possible samples, an unbiased
estimator gets the right answer.</p>
</section>
<p>Any single estimate from an unbiased estimator might be far from the
truth. But the errors balance out—sometimes we overestimate, sometimes
we underestimate, and on average we hit the bullseye.</p>
<section id="question-is-the-sample-mean-unbiased" class="callout-tip"
data-icon="false" data-collapse="true">
<h2>Question: Is the sample mean unbiased?</h2>
<p>Yes! The sample mean <span class="math inline">\bar{Y} =
\frac{1}{n}\sum_{i=1}^{n} Y_i</span> is an unbiased estimator of the
population mean <span class="math inline">\mu</span>. Here’s the
proof:</p>
<p><span class="math display">
\mathbb{E}[\bar{Y}] = \mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}
Y_i\right] = \frac{1}{n}\sum_{i=1}^{n} \mathbb{E}[Y_i] = \frac{1}{n}
\cdot n\mu = \mu
</span></p>
<p>Each <span class="math inline">Y_i</span> is drawn from the
population, so <span class="math inline">\mathbb{E}[Y_i] = \mu</span>
for all <span class="math inline">i</span>.</p>
</section>
<h3 id="the-abundance-of-unbiased-estimators">The Abundance of Unbiased
Estimators</h3>
<p>Here’s something remarkable: for a sample of size 2, there are
infinitely many unbiased estimators of the population mean! Any weighted
average of the form:</p>
<p><span class="math display">
\hat{\mu} = w_1 Y_1 + w_2 Y_2 \quad \text{where } w_1 + w_2 = 1
</span></p>
<p>is an unbiased estimator. For example: - <span
class="math inline">0.5 Y_1 + 0.5 Y_2</span> (the sample mean) - <span
class="math inline">0.1 Y_1 + 0.9 Y_2</span> - <span
class="math inline">0.8 Y_1 + 0.2 Y_2</span></p>
<p>All of these are unbiased! So if unbiasedness is all we care about,
we could pick any of these weighted averages. But surely some are better
than others. This leads us to our second criterion.</p>
<h3 id="efficiency-achieving-precision">Efficiency: Achieving
Precision</h3>
<p>Look carefully at the sampling distributions of different unbiased
estimators. You’ll notice something important: some have smaller
variance than others. An estimator with smaller variance gives us more
<em>precise</em> estimates—they cluster more tightly around the
parameter value.</p>
<section id="definition-efficiency" class="callout-important"
data-icon="false">
<h2>Definition: Efficiency</h2>
<p>Among all unbiased estimators of a parameter, the most
<strong>efficient</strong> estimator is the one with the smallest
variance in its sampling distribution.</p>
</section>
<p>Consider our sample of size 2 from the population <span
class="math inline">\{1, 2, 3\}</span>. The variances of different
unbiased estimators are:</p>
<table>
<thead>
<tr>
<th>Estimator</th>
<th>Variance</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="math inline">Y_1</span> (first observation only)</td>
<td><span class="math inline">\sigma^2 = 2/3</span></td>
</tr>
<tr>
<td><span class="math inline">Y_2</span> (second observation only)</td>
<td><span class="math inline">\sigma^2 = 2/3</span></td>
</tr>
<tr>
<td><span class="math inline">0.1Y_1 + 0.9Y_2</span></td>
<td><span class="math inline">0.82\sigma^2</span></td>
</tr>
<tr>
<td><span class="math inline">0.8Y_1 + 0.2Y_2</span></td>
<td><span class="math inline">0.68\sigma^2</span></td>
</tr>
<tr>
<td><span class="math inline">\bar{Y} = \frac{Y_1 + Y_2}{2}</span></td>
<td><span class="math inline">\frac{\sigma^2}{2} = 1/3</span></td>
</tr>
</tbody>
</table>
<p>The sample mean has the smallest variance! It turns out that among
all unbiased estimators of the population mean, the sample mean is the
most efficient—it has the minimum possible variance. This remarkable
result is known as the <strong>Gauss-Markov theorem</strong>.</p>
<h3 id="consistency-convergence-with-more-data">Consistency: Convergence
with More Data</h3>
<p>Both unbiasedness and efficiency are properties that hold for a fixed
sample size. But what happens as we gather more data? This brings us to
our third fundamental property.</p>
<section id="definition-consistency" class="callout-important"
data-icon="false">
<h2>Definition: Consistency</h2>
<p>An estimator <span class="math inline">\hat{\theta}</span> is
<strong>consistent</strong> if it converges in probability to the
parameter value as the sample size approaches infinity. Formally, for
any <span class="math inline">\epsilon &gt; 0</span>:</p>
<p><span class="math display">
\lim_{n \to \infty} P(|\hat{\theta} - \theta| &gt; \epsilon) = 0
</span></p>
<p>In plain language: as we gather more data, the probability that our
estimate is far from the parameter approaches zero.</p>
</section>
<p>For the sample mean, we can see consistency directly from its
variance:</p>
<p><span class="math display">
\mathrm{Var}(\bar{Y}) = \frac{\sigma^2}{n}
</span></p>
<p>As <span class="math inline">n</span> increases, the variance shrinks
toward zero. The sampling distribution collapses to a spike at <span
class="math inline">\mu</span>. This is the <strong>Law of Large
Numbers</strong>—one of the most fundamental theorems in probability and
statistics.</p>
<section id="the-law-of-large-numbers" class="callout-note"
data-icon="false">
<h2>The Law of Large Numbers</h2>
<p>As the sample size <span class="math inline">n</span> approaches
infinity, the sample mean <span class="math inline">\bar{Y}</span>
converges to the population mean <span class="math inline">\mu</span>.
Formally:</p>
<p><span class="math display">
\bar{Y} \xrightarrow{P} \mu \quad \text{as } n \to \infty
</span></p>
<p>This theorem is what makes empirical knowledge possible. It tells us
that our effort in collecting more data is worthwhile—more data leads to
better estimates.</p>
</section>
<section id="the-gamblers-fallacy" class="callout-warning"
data-icon="false">
<h2>The Gambler’s Fallacy</h2>
<p>The Law of Large Numbers is often misunderstood. Consider flipping a
fair coin ten times and getting heads all ten times. Many people reason:
“The coin should come up heads 50% of the time in the long run. I’ve
gotten too many heads, so tails are ‘due’—the next flip is more likely
to be tails.”</p>
<p>This reasoning is <strong>completely wrong</strong>! Each flip is
independent. The probability of heads on the eleventh flip is still
exactly 50%. The coin has no memory and no desire for balance.</p>
<p>The Law of Large Numbers says that as <span
class="math inline">n</span> grows large, the <em>probability</em> that
the proportion deviates far from 50% becomes small. It does not say that
outcomes will “even out” in any deterministic way.</p>
</section>
<h2 id="the-broader-landscape-of-estimator-properties">The Broader
Landscape of Estimator Properties</h2>
<p>Unbiasedness, efficiency, and consistency are the “big three”
properties, but statisticians have identified many others.</p>
<h3 id="sufficiency">Sufficiency</h3>
<p>An estimator is <strong>sufficient</strong> if it captures all the
information in the sample relevant to the parameter. Once you know the
value of a sufficient statistic, the individual observations provide no
additional information about the parameter.</p>
<p>For estimating the mean of a normal distribution, the sample mean is
sufficient. If I tell you <span class="math inline">\bar{Y} = 10</span>,
knowing that the individual observations were 8, 9, 10, 11, 12 tells you
nothing more about <span class="math inline">\mu</span>.</p>
<h3 id="robustness">Robustness</h3>
<p>An estimator is <strong>robust</strong> if it performs well even when
distributional assumptions are violated. The sample mean is sensitive to
outliers—a single extreme value can drastically shift it. The sample
median, by contrast, is highly robust to outliers.</p>
<h3 id="properties-are-distinct">Properties Are Distinct</h3>
<p>It’s crucial to understand that these properties are distinct—an
estimator can possess one without possessing another.</p>
<p><strong>Consistent but biased</strong>: Consider estimating
population variance using: <span class="math display">
\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(Y_i - \bar{Y})^2
</span></p>
<p>This is consistent (converges to <span
class="math inline">\sigma^2</span> as <span class="math inline">n \to
\infty</span>) but biased—its expected value is <span
class="math inline">\frac{n-1}{n}\sigma^2</span>, which underestimates
the variance. The unbiased version divides by <span
class="math inline">n-1</span> instead of <span
class="math inline">n</span>.</p>
<p><strong>Unbiased but inefficient</strong>: Using just the first
observation <span class="math inline">\hat{\mu} = Y_1</span> is unbiased
but spectacularly inefficient. Its variance is <span
class="math inline">\sigma^2</span>, compared to <span
class="math inline">\sigma^2/n</span> for the sample mean. You’re
throwing away all but one observation!</p>
<h2 id="navigating-tradeoffs">Navigating Tradeoffs</h2>
<p>When properties conflict, statisticians must choose which to
prioritize.</p>
<h3 id="the-classical-approach-prioritizing-unbiasedness">The Classical
Approach: Prioritizing Unbiasedness</h3>
<p>Traditional frequentist statistics often prioritizes unbiasedness.
The reasoning: if our method is systematically biased, we’re building
error into our procedure from the start. Better to be right on average
with high variance than systematically wrong with low variance.</p>
<h3 id="modern-approaches-the-bias-variance-tradeoff">Modern Approaches:
The Bias-Variance Tradeoff</h3>
<p>Sometimes we might accept a small amount of bias to achieve a large
reduction in variance. This insight drives modern techniques like ridge
regression and regularization methods.</p>
<section id="mean-squared-error" class="callout-important"
data-icon="false">
<h2>Mean Squared Error</h2>
<p>The <strong>mean squared error (MSE)</strong> combines bias and
variance into a single measure:</p>
<p><span class="math display">
\text{MSE}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \theta)^2] =
\text{Bias}(\hat{\theta})^2 + \mathrm{Var}(\hat{\theta})
</span></p>
<p>An estimator with small MSE might have some bias but sufficiently low
variance that its overall performance is superior to an unbiased but
high-variance alternative.</p>
</section>
<p>The bias-variance tradeoff, quantified through MSE, has become one of
the central organizing principles of modern statistical learning.</p>
<h2 id="summary">Summary</h2>
<p>We’ve established that the sample mean possesses three fundamental
and universally valued properties:</p>
<ol type="1">
<li><strong>Unbiasedness</strong>: On average, across all possible
samples, it equals the population mean</li>
<li><strong>Efficiency</strong>: Among unbiased estimators, it has the
smallest variance</li>
<li><strong>Consistency</strong>: As sample size grows, it converges to
the population mean</li>
</ol>
<p>These properties make the sample mean a natural and powerful choice
for estimating population means. But the landscape of estimator
properties is rich—different problems call for different priorities, and
understanding the tradeoffs among properties is essential for becoming a
sophisticated statistical thinker.</p>
